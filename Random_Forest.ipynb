{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e2b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_based_models.decision_tree import DecisionTree\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from numpy import sqrt\n",
    "from scipy.stats import mode\n",
    "from numpy import log2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a1ca6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f59775df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bootstrap(y,n_estimators): \n",
    "    # this function generates n_estimators lists of indices of size num_instances of y \n",
    "    # dim: n_estimators * len(y)\n",
    "    num_instances = y.shape[0]\n",
    "    indices = randint(0,high=num_instances,size=(n_estimators,num_instances)) # bootstrap with replacement\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b528e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not explain too much detail since the code should be self explainatory after going through Deccision Tree notebook\n",
    "class RandomForest:\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_estimators=100,\n",
    "                 criterion='gini',\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=5,\n",
    "                 max_features='sqrt',\n",
    "                 random_state=None):\n",
    "        self.n_estimators = n_estimators  # how many trees in the forest\n",
    "        self.criterion = criterion  # gini or entropy\n",
    "        self.max_depth = max_depth  # int or None\n",
    "        self.min_samples_split = min_samples_split  # int or None\n",
    "        self.max_features = max_features  # 'sqrt' or 'log2'; maximum features considered at each split\n",
    "        self.random_state = random_state\n",
    "        self.estimators = [\n",
    "        ]  # stores n_estimators number of estimators (trees)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.estimators = []\n",
    "        if self.max_features == 'sqrt':\n",
    "            n_features = round(sqrt(X.shape[1]))\n",
    "        elif self.max_features == 'log2':\n",
    "            n_features = round(log2(X.shape[1]))\n",
    "        elif self.max_features == None:\n",
    "            n_features = X.shape[1]\n",
    "        np.random.seed(self.random_state)\n",
    "        indices_array = Bootstrap(y, self.n_estimators)\n",
    "        # X_samples dim: n_estimators * n * k\n",
    "        # y_samples dim: n_estimators * n\n",
    "        X_samples, y_samples = X[indices_array], y[indices_array]\n",
    "        for i in range(self.n_estimators):\n",
    "            tree = DecisionTree(loss_func=self.criterion,\n",
    "                                max_depth=self.max_depth,\n",
    "                                min_samples_split=self.min_samples_split,\n",
    "                                max_features=n_features,\n",
    "                                random_state=i)\n",
    "            tree.fit(X_samples[i], y_samples[i])\n",
    "            self.estimators.append(tree)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # dim: n_estimators * len(X)\n",
    "        y_preds = np.array([tree.predict(X) for tree in self.estimators])\n",
    "        # dim: len(X)\n",
    "        y_preds = mode(y_preds)[0][0]\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86943ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8134328358208955\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('titanic.csv',\n",
    "                     usecols=[\n",
    "                         'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
    "                         'Fare', 'Embarked'\n",
    "                     ])\n",
    "    df.isna().sum()\n",
    "\n",
    "    y = df['Survived']\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=42)\n",
    "\n",
    "    ### Do some imputation since algorithms cannot handle missing values\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    imp = SimpleImputer(strategy='mean')\n",
    "    X_train[['Age']] = imp.fit_transform(X_train[['Age']])\n",
    "\n",
    "    imp2 = SimpleImputer(strategy='most_frequent')\n",
    "    X_train[['Embarked']] = imp2.fit_transform(X_train[['Embarked']])\n",
    "\n",
    "    # Prepare train and test data\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.compose import make_column_transformer\n",
    "\n",
    "    ohe = OneHotEncoder()\n",
    "    ct = make_column_transformer((ohe, ['Sex', 'Embarked']),\n",
    "                                 remainder='passthrough')\n",
    "    X_train_vect = ct.fit_transform(X_train)\n",
    "    y_train = y_train.values\n",
    "\n",
    "    X_test[['Age']] = imp.transform(X_test[['Age']])\n",
    "    X_test[['Embarked']] = imp2.transform(X_test[['Embarked']])\n",
    "    X_test_vect = ct.transform(X_test)\n",
    "    y_test = y_test.values\n",
    "    model = RandomForest(criterion='gini',\n",
    "                         min_samples_split=10,\n",
    "                         max_depth=5,\n",
    "                         random_state=4,\n",
    "                         max_features='log2')\n",
    "    model.fit(X_train_vect, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_vect)\n",
    "\n",
    "    accuracy = sum(y_pred == y_test) / len(y_test)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c21eecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9122807017543859\n",
      "92.95777940750122 s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Imports\n",
    "    from time import time\n",
    "    t0 = time()\n",
    "    from sklearn import datasets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    def accuracy(y_true, y_pred):\n",
    "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "        return accuracy\n",
    "\n",
    "    data = datasets.load_breast_cancer()\n",
    "    X, y = data.data, data.target\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=1234)\n",
    "\n",
    "    clf = RandomForest(max_depth=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n",
    "\n",
    "    t1 = time()\n",
    "\n",
    "    total = t1 - t0\n",
    "    print(total, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb6b39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.12033486366272 s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "rf = RandomForest(n_estimators=100, max_depth=5)\n",
    "rf.fit(X_train, y_train)\n",
    "t1 = time()\n",
    "\n",
    "total = t1 - t0\n",
    "print(total, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa9fc4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d7e88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfde1e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13984298706054688 s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "rf.fit(X_train, y_train)\n",
    "t1 = time()\n",
    "\n",
    "total = t1 - t0\n",
    "print(total, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce8cb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989fe86b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
